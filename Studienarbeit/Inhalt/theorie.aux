\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Theorie}{2}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
<<<<<<< HEAD
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Neuronales Netzwerk}{2}{section.2.1}}
=======
\@writefile{toc}{\contentsline {section}{\numberline {2.1}SetlX}{2}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}MNIST}{2}{section.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Neuronales Netzwerk}{2}{section.2.3}}
>>>>>>> 2b324f2aba8dd1d6f8180990cab1da67162e1a52
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Aufbau des neuronalen Netzwerks hinsichtlich der einzelnen Layer.}}{2}{figure.2.1}}
\newlabel{fig:neural_network_extended}{{2.1}{2}{Aufbau des neuronalen Netzwerks hinsichtlich der einzelnen Layer}{figure.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Perceptrons}{3}{section.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Percetron mit den Eingaben $x_1, x_2, x_3$ und der Ausgabe $\mathtt  {output}$.}}{3}{figure.2.2}}
\newlabel{fig:perceptron}{{2.2}{3}{Percetron mit den Eingaben $x_1, x_2, x_3$ und der Ausgabe $\mathtt {output}$}{figure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Unterschiedliche M\IeC {\"o}glichkeiten der Entscheidungsfindung.}}{4}{figure.2.3}}
\newlabel{fig:perceptron_models}{{2.3}{4}{Unterschiedliche MÃ¶glichkeiten der Entscheidungsfindung}{figure.2.3}{}}
<<<<<<< HEAD
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Sigmoid Funktion $\sigma (z)$.}}{4}{figure.2.4}}
\newlabel{fig:perceptron_plot}{{2.4}{4}{Sigmoid Funktion $\sigma (z)$}{figure.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Arbeitsweise von Perceptrons}{4}{section.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Percetron mit zwei Eingaben -2 und einem Bias von 3.}}{5}{figure.2.5}}
\newlabel{fig:perceptron_example}{{2.5}{5}{Percetron mit zwei Eingaben -2 und einem Bias von 3}{figure.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Halbaddierer mit den Eingaben $x_1$ und $x_2$.}}{5}{figure.2.6}}
\newlabel{fig:nand_gatter}{{2.6}{5}{Halbaddierer mit den Eingaben $x_1$ und $x_2$}{figure.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Halbaddierer-Aufbau mit Perceptrons.}}{5}{figure.2.7}}
\newlabel{fig:nand_gatter_perceptron}{{2.7}{5}{Halbaddierer-Aufbau mit Perceptrons}{figure.2.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Vereinfachter $\mathtt  {NAND}$ Gatter Aufbau mit Perceptrons.}}{6}{figure.2.8}}
\newlabel{fig:nand_gatter_perceptron_simplified}{{2.8}{6}{Vereinfachter $\mathtt {NAND}$ Gatter Aufbau mit Perceptrons}{figure.2.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Sigmoid Neurons}{6}{section.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Modifizieren von Weights und Biases schaffen lernendes Netzwerk.}}{6}{figure.2.9}}
\newlabel{fig:sigmoid_learning}{{2.9}{6}{Modifizieren von Weights und Biases schaffen lernendes Netzwerk}{figure.2.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Sigmoid Funktion $\sigma (z)$.}}{7}{figure.2.10}}
\newlabel{fig:sigmoid_plot}{{2.10}{7}{Sigmoid Funktion $\sigma (z)$}{figure.2.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Netzwerk zur Klassifizierung von handgeschrieben Zahlen}{8}{section.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Stochastic Gradient Descent}{8}{section.2.6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Backpropagation}{8}{section.2.7}}
=======
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Sigmoid Neurons}{4}{section.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Sigmoid Funktion $\sigma (z)$.}}{5}{figure.2.4}}
\newlabel{fig:perceptron_plot}{{2.4}{5}{Sigmoid Funktion $\sigma (z)$}{figure.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Modifizieren von Weights und Biases schaffen lernendes Netzwerk.}}{5}{figure.2.5}}
\newlabel{fig:sigmoid_learning}{{2.5}{5}{Modifizieren von Weights und Biases schaffen lernendes Netzwerk}{figure.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Sigmoid Funktion $\sigma (z)$.}}{6}{figure.2.6}}
\newlabel{fig:sigmoid_plot}{{2.6}{6}{Sigmoid Funktion $\sigma (z)$}{figure.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Sigmoid Funktion $\sigma (z)$.}}{6}{figure.2.7}}
\newlabel{fig:perceptron_plot}{{2.7}{6}{Sigmoid Funktion $\sigma (z)$}{figure.2.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Netzwerk zur Klassifizierung von handgeschrieben Zahlen}{7}{section.2.6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Architektur Neuronaler Netzwerke}{7}{section.2.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Architektur eines neuronalen Netzwerks.}}{7}{figure.2.8}}
\newlabel{fig:neural_network}{{2.8}{7}{Architektur eines neuronalen Netzwerks}{figure.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Aufbau des neuronalen Netzwerks hinsichtlich der einzelnen Layer.}}{8}{figure.2.9}}
\newlabel{fig:neural_network_extended}{{2.9}{8}{Aufbau des neuronalen Netzwerks hinsichtlich der einzelnen Layer}{figure.2.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Netzwerk zur Klassifizierung von handgeschrieben Zahlen}{8}{section.2.8}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Stochastic Gradient Descent}{8}{section.2.9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Backpropagation}{8}{section.2.10}}
>>>>>>> 2b324f2aba8dd1d6f8180990cab1da67162e1a52
\@setckpt{Inhalt/theorie}{
\setcounter{page}{9}
\setcounter{equation}{5}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
<<<<<<< HEAD
\setcounter{section}{7}
=======
\setcounter{section}{10}
>>>>>>> 2b324f2aba8dd1d6f8180990cab1da67162e1a52
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
<<<<<<< HEAD
\setcounter{figure}{10}
=======
\setcounter{figure}{9}
>>>>>>> 2b324f2aba8dd1d6f8180990cab1da67162e1a52
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{FancyVerbLine}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
<<<<<<< HEAD
\setcounter{bookmark@seq@number}{15}
=======
\setcounter{bookmark@seq@number}{18}
>>>>>>> 2b324f2aba8dd1d6f8180990cab1da67162e1a52
\setcounter{btxromaniannumeral}{0}
\setcounter{Definition}{0}
\setcounter{aufgabe}{0}
\setcounter{section@level}{1}
}
